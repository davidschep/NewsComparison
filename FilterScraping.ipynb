{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.parser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ny_post_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    date_string = date_string.replace('.m.', 'M').replace('ET', '').strip()\n",
    "    date_format = \"%b. %d, %Y, %I:%M %p\"\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_string, date_format)\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except ValueError:\n",
    "        df_row['day'] = np.nan\n",
    "        df_row['month'] = np.nan\n",
    "        df_row['year'] = np.nan\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_guardian_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    date_string = date_string.split(' ')[1:-1]\n",
    "    date_string = ' '.join(date_string).replace('.', ':')\n",
    "\n",
    "    date_format = \"%d %b %Y %H:%M\"\n",
    "\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_string, date_format)\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except ValueError:\n",
    "        df_row['day'] = np.nan\n",
    "        df_row['month'] = np.nan\n",
    "        df_row['year'] = np.nan\n",
    "    \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fox_news_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    date_string = date_string.replace('EST', '').replace('pm', 'PM').replace('am', 'AM').strip()\n",
    "    date_format_with_time = \"%B %d, %Y %I:%M%p\"\n",
    "    date_format_without_time = \"%B %d, %Y\"\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_string, date_format_with_time)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            parsed_date = datetime.strptime(date_string, date_format_without_time)\n",
    "        except ValueError:\n",
    "            df_row['day'] = np.nan\n",
    "            df_row['month'] = np.nan\n",
    "            df_row['year'] = np.nan\n",
    "            return df_row\n",
    "    df_row['day'] = parsed_date.day\n",
    "    df_row['month'] = parsed_date.month\n",
    "    df_row['year'] = parsed_date.year\n",
    "    \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_atlantic_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    try:\n",
    "        parsed_date = datetime.fromisoformat(date_string.rstrip('Z'))\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except ValueError:\n",
    "        df_row['day'] = np.nan\n",
    "        df_row['month'] = np.nan\n",
    "        df_row['year'] = np.nan\n",
    "    \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cnn_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    date_string = date_string.replace(' EST', '').replace(' EDT', '').strip()\n",
    "    date_format = \"%I:%M %p, %a %B %d, %Y\"\n",
    "\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_string, date_format)\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except ValueError:\n",
    "        df_row['day'] = np.nan\n",
    "        df_row['month'] = np.nan\n",
    "        df_row['year'] = np.nan\n",
    "    \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_business_insider_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    try:\n",
    "        parsed_date = datetime.fromisoformat(date_string.rstrip('Z'))\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except ValueError:\n",
    "        df_row['day'] = 'Unknown'\n",
    "        df_row['month'] = 'Unknown'\n",
    "        df_row['year'] = 'Unknown'\n",
    "    \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_washington_post_dates(df_row):\n",
    "    date_string = df_row['date']\n",
    "    try:\n",
    "        date_string = date_string.replace('at', '').replace('.m.', 'M').replace('EST', '').strip()\n",
    "        date_format = \"%B %d, %Y %I:%M %p\"\n",
    "        parsed_date = datetime.strptime(date_string, date_format)\n",
    "        df_row['day'] = parsed_date.day\n",
    "        df_row['month'] = parsed_date.month\n",
    "        df_row['year'] = parsed_date.year\n",
    "    except:\n",
    "        df_row['day'] = np.nan\n",
    "        df_row['month'] = np.nan\n",
    "        df_row['year'] = np.nan\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_row):\n",
    "    \"\"\"\n",
    "    Replaces reoccuring phrases in content which are not useful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_row['content'] = df_row['content'].replace('Î” Thanks for contacting us. We\\'ve received your submission.', '')\n",
    "        df_row['content'] = df_row['content'].replace('Fox News Flash top headlines are here. Check out what\\'s clicking on Foxnews.com', '')\n",
    "    except:\n",
    "        pass\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_joined_words(text):\n",
    "    \"\"\"\n",
    "    Separates words like 'JUSTin' which have a bunch of capital letters followed by a small letter which is the start of \n",
    "    another word\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pattern = re.compile(r'(?<=[a-z])(?=[A-Z])')\n",
    "        separated_text = pattern.sub(' ', text)\n",
    "        return separated_text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_scraped_data(df1):\n",
    "    \"\"\"\n",
    "    Takes unfiltered scraped dataframe as input and outputs filtered scraped dataframe\n",
    "    \"\"\"\n",
    "    df1.drop(['summary'],axis=1,inplace=True)\n",
    "    \n",
    "    date_info_dict = {\n",
    "            'NY Post': parse_ny_post_dates,\n",
    "            'Atlantic': parse_atlantic_dates,\n",
    "            'CNN': parse_cnn_dates,\n",
    "            'Business Insider': parse_business_insider_dates,\n",
    "            'Washington Post': parse_washington_post_dates,\n",
    "            'Fox News': parse_fox_news_dates,\n",
    "            'Guardian': parse_guardian_dates\n",
    "        }\n",
    "    \n",
    "    df1['day'] = np.nan\n",
    "    df1['month'] = np.nan\n",
    "    df1['year'] = np.nan\n",
    "\n",
    "    for name in date_info_dict:\n",
    "        df1[df1['name'] == name] = df1[df1['name'] == name].apply(date_info_dict[name], axis=1)\n",
    "    \n",
    "    df1.dropna(subset=['content'], inplace=True)\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df1 = df1.apply(clean_data, axis=1)\n",
    "    \n",
    "    df1['content'] = df1['content'].apply(separate_joined_words)\n",
    "    df1['title'] = df1['title'].apply(separate_joined_words)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20400\\3265723084.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfilter_scraped_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_scraping_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20400\\2945318173.py\u001b[0m in \u001b[0;36mfilter_scraped_data\u001b[1;34m(df1)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mTakes\u001b[0m \u001b[0munfiltered\u001b[0m \u001b[0mscraped\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0mscraped\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_filename' is not defined"
     ]
    }
   ],
   "source": [
    "filter_scraped_data(pd.read_csv('new_scraping_data.csv',index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
